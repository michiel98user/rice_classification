{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating live model drift monitoring: can you find which drift has occurred?\n",
    "\n",
    "**Exercise:** Your model has been in production for 5 years and you would like to assess whether model drift has occurred, and if so, why.\n",
    "\n",
    "During this exercise you will learn how to work with NannyML\n",
    "\n",
    "### Introduction to NannyML\n",
    "\n",
    "Data drift is mainly a problem when you expect it will impact model performance. However, it is not always possible to calculate model performance when collection of new ground truth labels is delayed or impossible.\n",
    "\n",
    "NannyML introduces so-called \"Nanny-models\" which **estimate the impact of data changes on \"child\" model performance without the need for new ground truth labels**. Besides, the package offers some handy prioritization and visualisation tools which may be helpful when performing a root-cause analysis when a harmful model drift has occurred.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMMENT THIS LINE AFTER THE FIRST RUN\n",
    "!pip install nannyml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nannyml as nml\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from random import uniform\n",
    "from configs.paths import FOLDER_CONFIG_FILES, FOLDER_DATA_RAW, FOLDER_MODELS\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from src.data.download_from_azure import download_data_from_azure_to_raw, read_config\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Revenue'\n",
    "\n",
    "num_cols = [\n",
    "    'Administrative',\n",
    "    'Administrative_Duration', \n",
    "    'Informational',\n",
    "    'Informational_Duration', \n",
    "    'ProductRelated', \n",
    "    'ProductRelated_Duration',\n",
    "    'BounceRates', \n",
    "    'ExitRates', \n",
    "    'PageValues', \n",
    "    'SpecialDay'\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    'Month',\n",
    "    'OperatingSystems',\n",
    "    'Browser',\n",
    "    'Region',\n",
    "    'TrafficType',\n",
    "    'VisitorType',\n",
    "    'Weekend'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset from Azure Blob storage using config file with credentials  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_name = \"config_metyis.yaml\" #put the correct company name here\n",
    "config = read_config(FOLDER_CONFIG_FILES / config_file_name)['azure-ld-best-practices']\n",
    "AZURE_STORAGE_CONNECTION_STRING = config['AZURE_STORAGE_CONNECTION_STRING']\n",
    "CONTAINER_NAME = config['CONTAINER_NAME']\n",
    "\n",
    "for i in range(5):\n",
    "    download_data_from_azure_to_raw(\n",
    "        filename=f\"online_shoppers_intention_{2018+i}.csv\",\n",
    "        azure_storage_connection_string=AZURE_STORAGE_CONNECTION_STRING,\n",
    "        container_name=CONTAINER_NAME,\n",
    "        folder_data_raw = FOLDER_DATA_RAW\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing data for NannyML\n",
    "Prepare the dataset to work with the package and compare the _analysis_ dataset with the _reference_ dataset used in training\n",
    "\n",
    "NannyML requires the following columns for the reference and analysis datasets:\n",
    "- y_pred_proba (based on a pre-trained model: use your own if possible)\n",
    "- y_pred (based on a pre-trained model: use your own if possible)\n",
    "- identifier (see script below)\n",
    "- timestamp (see script below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reference (train) dataset\n",
    "reference= (\n",
    "    pd.read_csv(FOLDER_DATA_RAW / \"online_shoppers_intention.csv\")\n",
    "    .astype({col:\"category\" for col in cat_cols})\n",
    "    .assign(\n",
    "        identifier = lambda d: d.index,\n",
    "        timestamp = pd.Timestamp(f\"2017-01-01\"),\n",
    "    )\n",
    ")\n",
    "display(reference.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your fitted model here or fit a model using the code below\n",
    "fitted_model = joblib.load(FOLDER_MODELS / \"fitted_model.pkl\")\n",
    "\n",
    "# Comment the following code in this cell if you use your own model\n",
    "X = reference.drop(columns=\"Revenue\")\n",
    "y = reference[\"Revenue\"]\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n",
    "clf = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", LogisticRegression())]\n",
    ")\n",
    "fitted_model = clf.fit(X, y)\n",
    "fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the unseen analysis datasets\n",
    "analysis_datasets = [\n",
    "    pd.read_csv(FOLDER_DATA_RAW / f\"online_shoppers_intention_{2018+i}.csv\")\n",
    "    .assign(timestamp = pd.Timestamp(f\"{2018+i}-01-01\")) \n",
    "    for i in range(5)\n",
    "]\n",
    "analysis = pd.concat(analysis_datasets).assign(identifier = lambda d: d.index)\n",
    "display(analysis.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which predict_proba outcome refers to the \"True\" class\n",
    "class_index = np.where(fitted_model.classes_)[0][0]\n",
    "\n",
    "# Add y_pred_proba and y_pred to analysis dataset\n",
    "reference = reference.assign(\n",
    "    y_pred = fitted_model.predict(X),\n",
    "    y_pred_proba = fitted_model.predict_proba(X)[:,class_index],    \n",
    ")\n",
    "\n",
    "analysis = analysis.assign(\n",
    "    y_pred = fitted_model.predict(analysis),\n",
    "    y_pred_proba = fitted_model.predict_proba(analysis)[:,class_index],    \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis using NannyML\n",
    "The _performance estimator_ and _univariate drift calculator_ have already been implemented for you below.\n",
    "You can refer to for example the [quickstart manual](https://nannyml.readthedocs.io/en/stable/quick.html) to understand other functionalities that may be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a chunker or set a chunk size\n",
    "chunk_period = \"1Y\"\n",
    "\n",
    "# initialize, specify required data columns, fit estimator and estimate\n",
    "estimator = nml.CBPE(\n",
    "    y_pred_proba='y_pred_proba',\n",
    "    y_pred='y_pred',\n",
    "    y_true='Revenue',\n",
    "    metrics=['roc_auc'],\n",
    "    timestamp_column_name='timestamp',\n",
    "    chunk_period=chunk_period,\n",
    "    problem_type='classification_binary',\n",
    ")\n",
    "estimator = estimator.fit(reference)\n",
    "estimated_performance = estimator.estimate(analysis)\n",
    "\n",
    "# Show results\n",
    "figure = estimated_performance.plot()\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_column_names = num_cols + cat_cols\n",
    "\n",
    "# Let's initialize the object that will perform the Univariate Drift calculations\n",
    "univariate_calculator = nml.UnivariateDriftCalculator(\n",
    "    column_names=feature_column_names,\n",
    "    timestamp_column_name='timestamp',\n",
    "    chunk_period=chunk_period,\n",
    "    continuous_methods=['kolmogorov_smirnov', 'jensen_shannon'],\n",
    "    categorical_methods=['chi2', 'jensen_shannon'],\n",
    ")\n",
    "univariate_calculator = univariate_calculator.fit(reference)\n",
    "univariate_results = univariate_calculator.calculate(analysis)\n",
    "\n",
    "# Plot drift results for all continuous columns\n",
    "figure = (univariate_results\n",
    "    .filter(\n",
    "        column_names=univariate_results.continuous_column_names, \n",
    "        methods=['jensen_shannon']\n",
    "    )\n",
    "    .plot(kind='distribution')\n",
    ")\n",
    "figure.show()\n",
    "\n",
    "# Plot drift results for all categorical columns\n",
    "figure = (univariate_results\n",
    "    .filter(\n",
    "        column_names=univariate_results.categorical_column_names, \n",
    "        methods=['chi2']\n",
    "    )\n",
    "    .plot(kind='drift')\n",
    ")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ld_bp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dbc63c55169f424b4fe0b771ab6bd8a3ecda49525ac1f981102901d28d0b0d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
