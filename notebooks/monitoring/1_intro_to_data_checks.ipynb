{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d8f69f4-9f32-464d-91e2-17d34dd2eb28",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20ee9f34-b91c-4dbf-9cb3-c42264acb74f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from configs.paths import FILE_PATH_RAW\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff70d819-e899-49c5-8730-8359aca7d452",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'Revenue' # categorical variable\n",
    "\n",
    "num_cols = ['Administrative',\n",
    "            'Administrative_Duration', \n",
    "            'Informational',\n",
    "            'Informational_Duration', \n",
    "            'ProductRelated', \n",
    "            'ProductRelated_Duration',\n",
    "            'BounceRates', \n",
    "            'ExitRates', \n",
    "            'PageValues', \n",
    "            'SpecialDay']\n",
    "\n",
    "cat_cols = ['Month',\n",
    "            'OperatingSystems',\n",
    "            'Browser',\n",
    "            'Region',\n",
    "            'TrafficType',\n",
    "            'VisitorType',\n",
    "            'Weekend']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FILE_PATH_RAW)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll split the original dataset in 2 parts:\n",
    "* `df_current`: we'll pretend this is the dataset we used to train model currently in production\n",
    "* `df_new`: we'll pretend this is the new data arriving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current = df.sample(frac=0.7, random_state=1)\n",
    "df_new = df.drop(df_current.index)\n",
    "\n",
    "print(f'Original df shape: {df.shape}')\n",
    "print(f'Current df shape: {df_current.shape}')\n",
    "print(f'New data df shape: {df_new.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to model drift simulation\n",
    "\n",
    "**Scenario:**\n",
    "1. During the upstream data cleansing process, visitors from certain OperatingSystem (\"1\",\"2\") are missing their `VisitorType` entries\n",
    "2. During the upstream data generation procedure the month \"June\" from `Month` is wrongly inserted as \"Jul\"\n",
    "3. Also pretending that the new data refers to a period of pandemic, we can imagine that `Informational_Duration` and `ProductRelated_Duration` increase by double during normal days (`SpecialDay`=0).\n",
    "  \n",
    "**What are we simulating here?**\n",
    "* Feature drift\n",
    "* Upstream data errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating model drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_err = df_new.copy()\n",
    "\n",
    "# 1) null VisitorType for OperatingSystems like 1,2:\n",
    "df_1_err.loc[df_1_err[\"OperatingSystems\"].isin([1,2]), \"VisitorType\"] = np.nan\n",
    "\n",
    "# 2) \"June\" --> \"Jun\":\n",
    "df_1_err.loc[df_1_err[\"Month\"]==\"June\", \"Month\"] = \"Jul\"\n",
    "\n",
    "#3) double value of Informational_Duration and ProductRelated_Duration when SpecialDay=0:\n",
    "df_1_err.loc[df_1_err[\"SpecialDay\"]==0,[\"Informational_Duration\",\"ProductRelated_Duration\"]] = 2* df_1_err.loc[df_1_err[\"SpecialDay\"]==0,[\"Informational_Duration\",\"ProductRelated_Duration\"]]\n",
    "\n",
    "df_1_err.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0c11a27-f1f8-4f6f-96c0-b1efe11f38dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Feature checks prior to model training\n",
    "\n",
    "**1. All features**\n",
    "* Null checks\n",
    "\n",
    "**2. Numeric features**\n",
    "* Summary statistic checks: mean, median, standard deviation, minimum, maximum\n",
    "* Distribution checks\n",
    "\n",
    "**3. Categorical features**\n",
    "* Check expected count for each level\n",
    "* Check the mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set threshold\n",
    "You can fine-tune these threshold to impact the number of (false) alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "062cf916-840a-41d3-b7da-715bdbb9c45f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_proportion_threshold = 0.3     # how much we should allow null values presence \n",
    "stats_threshold_limit = 0.5         # how much we should allow basic summary stats to shift \n",
    "p_threshold = 0.05                  # the p-value below which to reject null hypothesis "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea111622-1a5e-45e3-925a-ea985af09287",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 1 - Null checks\n",
    "\n",
    "Write a piece of code that return any features of `df_1_err` that exceed the specified null threshold (`null_proportion_threshold)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a97c9809-656a-4e5e-ad4f-eba680fce723",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"CHECKING PROPORTION OF NULLS.....\\n\")\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Numeric features --> Summary statistic checks\n",
    "\n",
    "* Check if the summary stats of new data (`df_1_err`) significantly deviates from the summary stats in the production data (`df_current`) by a certain threshold `stats_threshold_limit`\n",
    "* You should consider all the metrics defined below in `statistic_list` variable.\n",
    "\n",
    "\n",
    "For example the code should print an alarm if, for a numeric variable \"var1\":<br>\n",
    "mean(new_data.var1) < or > mean(prod_data.var1) x `stats_threshold_limit` <br>\n",
    "The printed message also should contain absolute value for that metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_list = [\"mean\", \"median\", \"std\", \"min\", \"max\"]\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each features that exceed the `stats_threshold_limit` for at least one metric, plot that feature's distributions (e.g. boxplot) for both the datasets in order to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Let's look at the box plots of the features that exceed the stats_threshold_limit of {stats_threshold_limit}:\\n\")\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Numeric features --> Distribution checks\n",
    "\n",
    "* Perform Levene test (https://en.wikipedia.org/wiki/Levene%27s_test) to check if each column's variance in new_df is significantly different from reference_df\n",
    "* Perform also Kolmogorov-Smirnov test (https://en.wikipedia.org/wiki/Kolmogorovâ€“Smirnov_test) <br>\n",
    "\n",
    "For both tests you should print all the features which are significantly different between the two dataset, comparing the obtained p_value with `p_threshold`. <br>\n",
    "You can use python module `scipy.stats` to implement the tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCHECKING VARIANCES WITH LEVENE TEST.....\\n\")\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCHECKING KS TEST.....\\n\")\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Categorical features\n",
    "\n",
    "* Check if there are different number of level for each categorical variable between the incoming data and the data in production.\n",
    "* Check for each categorical variable if the mode has changed\n",
    "* Perform chi-square test with `p_threshold` (python module `scipy.stats`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCHECKING if different number of levels.....\\n\")\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCHECKING if mode has changed.....\\n\")\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCHECKING CHI-SQUARED TEST.....\\n\")\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each categorical features found in the previous checks, plot their categories feature's distributions (e.g. barplot) for both the datasets in order to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nVisualizing categories frequency distribution for features found in the previous checks:\\n\")\n",
    "\n",
    "# INSERT YOUR CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "datadrift_notebook",
   "notebookOrigID": 4447609022720764,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "env_ld_bp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8dbc63c55169f424b4fe0b771ab6bd8a3ecda49525ac1f981102901d28d0b0d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
